{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to import conll\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('./src/'))\n",
    "\n",
    "from conll import evaluate\n",
    "# for nice tables\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified version to support fst-output\n",
    "def read_fst4conll(fst_file, fs=\"\\t\", oov='<unk>', otag='O', sep='+', split=False):\n",
    "    \"\"\"\n",
    "    :param corpus_file: corpus in conll format\n",
    "    :param fs: field separator\n",
    "    :param oov: token to map to otag (we need to get rid of <unk> in labels)\n",
    "    :param otag: otag symbol\n",
    "    :param sep: \n",
    "    :param split:\n",
    "    :return: corpus \n",
    "    \"\"\"\n",
    "    sents = []  # list to hold words list sequences\n",
    "    words = []  # list to hold feature tuples\n",
    "\n",
    "    for line in open(fst_file):\n",
    "        line = line.strip()\n",
    "        if len(line.strip()) > 0:\n",
    "            feats = tuple(line.strip().split(fs))\n",
    "            # arc has minimum 3 columns, else final state\n",
    "            if len(feats) >= 3:\n",
    "                ist = feats[2]  # 3rd column (input)\n",
    "                ost = feats[3]  # 4th column (output)\n",
    "                # replace '<unk>' with 'O'\n",
    "                ost = otag if ost == oov else ost\n",
    "                # ignore for now\n",
    "                ost = ost.split(sep)[1] if split and ost != otag else ost\n",
    "                \n",
    "                words.append((ist, ost))\n",
    "            else:\n",
    "                sents.append(words)\n",
    "                words = []\n",
    "        else:\n",
    "            if len(words) > 0:\n",
    "                sents.append(words) \n",
    "                words = []\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus_conll(corpus_file, fs=\"\\t\"):\n",
    "    \"\"\"\n",
    "    read corpus in CoNLL format\n",
    "    :param corpus_file: corpus in conll format\n",
    "    :param fs: field separator\n",
    "    :return: corpus\n",
    "    \"\"\"\n",
    "    featn = None  # number of features for consistency check\n",
    "    sents = []  # list to hold words list sequences\n",
    "    words = []  # list to hold feature tuples\n",
    "\n",
    "    for line in open(corpus_file):\n",
    "        line = line.strip()\n",
    "        if len(line.strip()) > 0:\n",
    "            feats = tuple(line.strip().split(fs))\n",
    "            if not featn:\n",
    "                featn = len(feats)\n",
    "            elif featn != len(feats) and len(feats) != 0:\n",
    "                raise ValueError(\"Unexpected number of columns {} ({})\".format(len(feats), featn))\n",
    "\n",
    "            words.append(feats)\n",
    "        else:\n",
    "            if len(words) > 0:\n",
    "                sents.append(words)\n",
    "                words = []\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_frequency_list(corpus):\n",
    "    \"\"\"\n",
    "    create frequency list for a corpus\n",
    "    :param corpus: corpus as list of lists\n",
    "    \"\"\"\n",
    "    frequencies = {}\n",
    "    for sent in corpus:\n",
    "        for token in sent:\n",
    "            frequencies[token] = frequencies.setdefault(token, 0) + 1\n",
    "    return frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutoff(corpus, tf_min=2):\n",
    "    \"\"\"\n",
    "    apply min cutoffs\n",
    "    :param tf_min: minimum token frequency for lexicon elements (below removed); default 2\n",
    "    :return: lexicon as set\n",
    "    \"\"\"\n",
    "    frequencies = compute_frequency_list(corpus)\n",
    "    return sorted([token for token, frequency in frequencies.items() if frequency >= tf_min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "dpath='dataset/NL2SparQL4NLU'\n",
    "temp_folder='tmp'\n",
    "\n",
    "mkdir -p $temp_folder\n",
    "\n",
    "cp $dpath.train.utterances.txt $temp_folder/trn.txt\n",
    "cp $dpath.test.utterances.txt $temp_folder/tst.txt\n",
    "\n",
    "cp $dpath.train.conll.txt $temp_folder/trn.conll\n",
    "cp $dpath.test.conll.txt $temp_folder/tst.conll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = 'tmp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data in utterance-per-line format for output symbols (w+t)\n",
    "trn = read_corpus_conll(temp_folder + 'trn.conll')\n",
    "wt_sents = [[\"+\".join(w) for w in s] for s in trn]\n",
    "wt_osyms = cutoff(wt_sents)\n",
    "wt_isyms = [w.split('+')[0] for w in wt_osyms]\n",
    "\n",
    "with open(temp_folder + 'trn.wt.txt', 'w') as f:\n",
    "    for s in wt_sents:\n",
    "        f.write(\" \".join(s) + \"\\n\")\n",
    "        \n",
    "with open(temp_folder + 'osyms.wt.lst.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(wt_osyms) + \"\\n\")\n",
    "    \n",
    "with open(temp_folder + 'isyms.wt.lst.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(wt_isyms) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "temp_folder='tmp'\n",
    "\n",
    "ngramsymbols $temp_folder/osyms.wt.lst.txt $temp_folder/osyms.wt.txt\n",
    "ngramsymbols $temp_folder/isyms.wt.lst.txt $temp_folder/isyms.wt.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of states                                       1096\n",
      "# of ngram arcs                                   6179\n",
      "# of backoff arcs                                 1095\n",
      "initial state                                     1\n",
      "unigram state                                     0\n",
      "# of final states                                 533\n",
      "ngram order                                       2\n",
      "# of 1-grams                                      1095\n",
      "# of 2-grams                                      5617\n",
      "well-formed                                       y\n",
      "normalized                                        y\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "temp_folder='tmp'\n",
    "\n",
    "# compile data into FAR\n",
    "farcompilestrings \\\n",
    "    --symbols=$temp_folder/osyms.wt.txt \\\n",
    "    --keep_symbols \\\n",
    "    --unknown_symbol='<unk>' \\\n",
    "    $temp_folder/trn.wt.txt $temp_folder/trn.wt.far\n",
    "\n",
    "# train ngram model\n",
    "ngramcount --order=2 $temp_folder/trn.wt.far $temp_folder/trn.wt.cnt\n",
    "ngrammake $temp_folder/trn.wt.cnt $temp_folder/wt2.lm\n",
    "ngraminfo $temp_folder/wt2.lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_w2t_wt(isyms, sep='+', out=temp_folder+'w2wt.tmp'):\n",
    "    special = {'<epsilon>', '<s>', '</s>'}\n",
    "    oov = '<unk>'  # unknown symbol\n",
    "    state = '0'    # wfst specification state\n",
    "    fs = \" \"       # wfst specification column separator\n",
    "    \n",
    "    ist = sorted(list(set([line.strip().split(\"\\t\")[0] for line in open(isyms, 'r')]) - special))\n",
    "    \n",
    "    with open(out, 'w') as f:\n",
    "        for e in ist:\n",
    "            f.write(fs.join([state, state, e.split(sep)[0], e]) + \"\\n\")\n",
    "        f.write(state + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_w2t_wt(temp_folder+'osyms.wt.txt', out=temp_folder+'w2wt_wt.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fst type                                          vector\n",
      "arc type                                          standard\n",
      "input symbol table                                tmp/isyms.wt.txt\n",
      "output symbol table                               tmp/osyms.wt.txt\n",
      "# of states                                       1\n",
      "# of arcs                                         1094\n",
      "initial state                                     0\n",
      "# of final states                                 1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "temp_folder='tmp'\n",
    "\n",
    "# Let's compile it\n",
    "fstcompile \\\n",
    "    --isymbols=$temp_folder/isyms.wt.txt \\\n",
    "    --osymbols=$temp_folder/osyms.wt.txt \\\n",
    "    --keep_isymbols \\\n",
    "    --keep_osymbols \\\n",
    "    $temp_folder/w2wt_wt.txt $temp_folder/w2wt_wt.bin\n",
    "\n",
    "fstinfo $temp_folder/w2wt_wt.bin | head -n 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "temp_folder='tmp'\n",
    "\n",
    "farcompilestrings \\\n",
    "    --symbols=$temp_folder/isyms.wt.txt \\\n",
    "    --keep_symbols \\\n",
    "    --initial_symbols=false \\\n",
    "    --unknown_symbol='<unk>' \\\n",
    "    $temp_folder/tst.txt $temp_folder/tst.wt.far\n",
    "\n",
    "wdir=$temp_folder/'wdir_wt'\n",
    "mkdir -p $wdir\n",
    "\n",
    "farextract --filename_prefix=\"$wdir/\" $temp_folder/tst.wt.far\n",
    "\n",
    "cp $wdir/tst.txt-0001 sent.wt.fsa\n",
    "\n",
    "fstprint $temp_folder/sent.wt.fsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t1\tstar\tstar+O\t7.93891811\n",
      "1\t2\tof\tof+O\t1.55421352\n",
      "2\t3\t<unk>\t<unk>\t2.84977818\n",
      "3\t1.10391009\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "temp_folder='tmp'\n",
    "\n",
    "fstcompose $temp_folder/sent.wt.fsa $temp_folder/w2wt_wt.bin | fstcompose - $temp_folder/wt2.lm | fstshortestpath | fstrmepsilon | fsttopsort | fstprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "temp_folder='tmp'\n",
    "wdir=$temp_folder/'wdir_wt'\n",
    "farr=($(ls $wdir))\n",
    "\n",
    "for f in ${farr[@]}\n",
    "do\n",
    "    fstcompose $wdir/$f $temp_folder/w2wt_wt.bin | fstcompose - $temp_folder/wt2.lm |\\\n",
    "        fstshortestpath | fstrmepsilon | fsttopsort | fstprint --isymbols=$temp_folder/isyms.wt.txt\n",
    "done > $temp_folder/w2wt_wt.wt2.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>movie.location</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character.name</th>\n",
       "      <td>0.667</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.381</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.gross_revenue</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director.nationality</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>award.category</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.type</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>award.ceremony</th>\n",
       "      <td>0.714</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.nationality</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.release_date</th>\n",
       "      <td>0.412</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.444</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.star_rating</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.genre</th>\n",
       "      <td>0.963</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.825</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.language</th>\n",
       "      <td>0.786</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.704</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director.name</th>\n",
       "      <td>0.639</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.601</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.type</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating.name</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.943</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.subject</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.675</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.release_region</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie.name</th>\n",
       "      <td>0.807</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.797</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person.name</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.603</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>producer.name</th>\n",
       "      <td>0.692</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.652</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country.name</th>\n",
       "      <td>0.629</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.667</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor.name</th>\n",
       "      <td>0.730</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.701</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.753</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.724</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          p      r      f     s\n",
       "movie.location        0.000  0.000  0.000     7\n",
       "character.name        0.667  0.267  0.381    15\n",
       "movie.gross_revenue   0.000  0.000  0.000     5\n",
       "director.nationality  1.000  0.000  0.000     1\n",
       "award.category        1.000  0.000  0.000     2\n",
       "movie.type            1.000  0.000  0.000     4\n",
       "award.ceremony        0.714  0.714  0.714     7\n",
       "actor.nationality     1.000  1.000  1.000     1\n",
       "movie.release_date    0.412  0.483  0.444    29\n",
       "movie.star_rating     1.000  0.000  0.000     1\n",
       "movie.genre           0.963  0.722  0.825    36\n",
       "movie.language        0.786  0.638  0.704    69\n",
       "director.name         0.639  0.568  0.601    81\n",
       "actor.type            1.000  1.000  1.000     2\n",
       "rating.name           0.935  0.951  0.943    61\n",
       "movie.subject         0.788  0.591  0.675    44\n",
       "movie.release_region  1.000  0.000  0.000     4\n",
       "movie.name            0.807  0.786  0.797   473\n",
       "person.name           0.655  0.559  0.603    34\n",
       "producer.name         0.692  0.616  0.652    73\n",
       "country.name          0.629  0.710  0.667    62\n",
       "actor.name            0.730  0.675  0.701    80\n",
       "total                 0.753  0.697  0.724  1091"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs = read_corpus_conll(temp_folder+'tst.conll')\n",
    "hyps = read_fst4conll(temp_folder+'w2wt_wt.wt2.out', split=True)\n",
    "\n",
    "results = evaluate(refs, hyps)\n",
    "\n",
    "pd_tbl = pd.DataFrame().from_dict(results, orient='index')\n",
    "pd_tbl.round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
